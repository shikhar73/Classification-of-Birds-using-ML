{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Files\n",
    "import os # os-operating system module\n",
    "import sys \n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # mathma\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading list of folders for the bird images\n",
    "imgs_list = os.listdir(\"./images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the images file\n",
    "f = open(\"images.txt\")\n",
    "data = f.read()\n",
    "data = data.split(\"\\n\")\n",
    "\n",
    "# Deleting Last Empty Element\n",
    "del(data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting image ID and image name\n",
    "imgs_id = []\n",
    "imgs_name = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    temp1 = data[i].split()\n",
    "    imgs_id.append(temp1[0])\n",
    "    imgs_name.append(temp1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading class files\n",
    "f = open(\"classes.txt\")\n",
    "data = f.read()\n",
    "data = data.split(\"\\n\")\n",
    "del(data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Names\n",
    "class_names = []\n",
    "for i in range(len(data)):\n",
    "    class_names.append(data[i].split()[1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training-Test Split\n",
    "f = open(\"train_test_split.txt\")\n",
    "data = f.read()\n",
    "data = data.split(\"\\n\")\n",
    "del(data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing images into training and testing sets\n",
    "train_test_ids = []\n",
    "for i in range(len(data)):\n",
    "    temp = data[i].split()[1]\n",
    "    train_test_ids.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Results Outputs\n",
    "f = open(\"image_class_labels.txt\")\n",
    "data = f.read()\n",
    "data = data.split(\"\\n\")\n",
    "del(data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_labels = []\n",
    "for i in range(len(data)):\n",
    "    temp = data[i].split()[1]\n",
    "    imgs_labels.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Training and Testing Set Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "train_labels = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to test images\n",
      "Adding to training image\n",
      "Adding to training image\n",
      "Adding to test images\n"
     ]
    }
   ],
   "source": [
    "# Looping through the image folders\n",
    "ID_COUNTER = 0\n",
    "for i in range(len(imgs_list)):\n",
    "    # Looping through individual folders and reading the images\n",
    "    temp = os.listdir(\"./images/\"+imgs_list[i])\n",
    "    for j in range(len(temp)):\n",
    "        img = cv2.imread(\"./images/\"+imgs_list[i]+\"/\"+temp[j])\n",
    "        if(int(train_test_ids[ID_COUNTER]) == 1):\n",
    "            print(\"Adding to training image\")\n",
    "            train_data.append(img)\n",
    "            train_labels.append(i)\n",
    "        else:\n",
    "            print(\"Adding to test images\")\n",
    "            test_data.append(img)\n",
    "            test_labels.append(i)\n",
    "            \n",
    "        ID_COUNTER += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to numpy arrays\n",
    "train_data = np.asarray(train_data)\n",
    "test_data = np.asarray(test_data)\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape\n",
      "(150,)\n",
      "Test Data Shape\n",
      "(132,)\n",
      "Train Labels Shape\n",
      "(150,)\n",
      "Test Labels Shape\n",
      "(132,)\n"
     ]
    }
   ],
   "source": [
    "# Checking Shapes of arrays\n",
    "print(\"Train Data Shape\")\n",
    "print(train_data.shape)\n",
    "\n",
    "print(\"Test Data Shape\")\n",
    "print(test_data.shape)\n",
    "\n",
    "print(\"Train Labels Shape\")\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(\"Test Labels Shape\")\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 346, 3)\n",
      "(500, 326, 3)\n"
     ]
    }
   ],
   "source": [
    "# Sample images\n",
    "print(test_data[100].shape)\n",
    "print(train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping whole dataset to have uniform shape\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "for i in range(len(train_data)):\n",
    "    new_train_data.append(cv2.resize(train_data[i], (300, 300), interpolation = cv2.INTER_AREA))\n",
    "for i in range(len(test_data)):\n",
    "    new_test_data.append(cv2.resize(test_data[i], (300, 300), interpolation = cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 346, 3)\n",
      "(500, 326, 3)\n"
     ]
    }
   ],
   "source": [
    "# Sample images after reshaping\n",
    "print(test_data[100].shape)\n",
    "print(train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = np.asarray(new_train_data)\n",
    "new_test_data = np.asarray(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 300, 300, 3)\n",
      "(132, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the data for CNN\n",
    "print(new_train_data.shape)\n",
    "print(new_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 346, 3)\n",
      "(500, 326, 3)\n"
     ]
    }
   ],
   "source": [
    "# Sample images after reshaping\n",
    "print(test_data[100].shape)\n",
    "print(train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the outputs\n",
    "from keras.utils import to_categorical # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode target column\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 300, 300, 3)\n",
      "(132, 300, 300, 3)\n",
      "(150, 5)\n",
      "(132, 5)\n"
     ]
    }
   ],
   "source": [
    "print(new_train_data.shape)\n",
    "print(new_test_data.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = np.reshape(new_train_data, (new_train_data.shape[0], 300*300*3))\n",
    "new_test_data = np.reshape(new_test_data, (new_test_data.shape[0], 300*300*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 270000)\n",
      "(132, 270000)\n",
      "(150, 5)\n",
      "(132, 5)\n"
     ]
    }
   ],
   "source": [
    "print(new_train_data.shape)\n",
    "print(new_test_data.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 300 #to change dataset\n",
    "n_test = 100 #to change dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = new_train_data[:n_train, :]\n",
    "new_test_data = new_test_data[:n_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:n_train]\n",
    "y_test = y_test[:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb.fit(new_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = clf_nb.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nb = accuracy_score(y_test, pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy\n",
      "0.49\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracy\")\n",
    "print(acc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC(kernel=\"linear\", C=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.025, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc.fit(new_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = clf_svc.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svc = accuracy_score(y_test, pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Accuracy\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine Accuracy\")\n",
    "print(acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(new_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = clf_rf.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf = accuracy_score(y_test, pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy\n",
      "0.28\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy\")\n",
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lda = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lda.fit(new_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = clf_lda.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lda = accuracy_score(y_test, pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy\n",
      "0.41\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Accuracy\")\n",
    "print(acc_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dt.fit(new_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = clf_dt.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dt = accuracy_score(y_test, pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy\n",
      "0.28\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Accuracy\")\n",
    "print(acc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn.fit(new_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = clf_knn.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = accuracy_score(y_test, pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy\n",
      "0.26\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Accuracy\")\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. One Vs Rest - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = LogisticRegression(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ovr.fit(new_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = clf_ovr.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ovr = accuracy_score(y_test, pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs Rest Logistic Regression Accuracy\n",
      "0.32\n"
     ]
    }
   ],
   "source": [
    "print(\"One vs Rest Logistic Regression Accuracy\")\n",
    "print(acc_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
